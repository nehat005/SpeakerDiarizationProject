# -*- coding: utf-8 -*-
"""pyannotate_inference.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-ugIhyQptpyEjm9dDxLmdF3w5oHsZESj
"""

# !pip install pyannotate
# !pip install https://github.com/pyannote/pyannote-audio/archive/develop.zip

from pyannote.audio import Pipeline

import torch

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using device:', device)
print()

# Additional Info when using cuda
if device.type == 'cuda':
    print(torch.cuda.get_device_name(0))

pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization",
                                    use_auth_token='USE_AUTHORIZATION_TOKEN_HERE')

# visit hf.co/settings/tokens to create an access token

# apply pretrained pipeline
diarization = pipeline('/data/SyntheticVerbmobil/dialog_MEM_MBS_2.wav')
# print the result
with open('out.rttm', 'w') as out_file:
  for turn, _, speaker in diarization.itertracks(yield_label=True):
    print(f"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}")
    duration = turn.end - turn.start
    out_file.write(f'SPEAKER dialog_MEM_MBS_2 1 {turn.start:.3f} {duration:.3f} <NA> <NA> {speaker} <NA> <NA>\n')